{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be16e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from game import Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49048e23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Game' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mGame\u001b[49m()\n\u001b[0;32m      2\u001b[0m tf_env \u001b[38;5;241m=\u001b[39m tf_py_environment\u001b[38;5;241m.\u001b[39mTFPyEnvironment(env)\n\u001b[0;32m      4\u001b[0m time_step \u001b[38;5;241m=\u001b[39m tf_env\u001b[38;5;241m.\u001b[39mreset()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Game' is not defined"
     ]
    }
   ],
   "source": [
    "env = Game()\n",
    "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "\n",
    "time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 5\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "  episode_reward = 0\n",
    "  episode_steps = 0\n",
    "  time_step = tf_env.reset()\n",
    "  while not time_step.is_last():\n",
    "    action = agent.policy.action(time_step)\n",
    "    time_step = tf_env.step(action)\n",
    "    episode_steps += 1\n",
    "    episode_reward += time_step.reward.numpy()\n",
    "  rewards.append(episode_reward)\n",
    "  steps.append(episode_steps)\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)\n",
    "\n",
    "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
    "print('avg_length', avg_length, 'avg_reward:', avg_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b51172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "board = np.array([[2,2,0,4],\n",
    "                  [4,16,8,4],\n",
    "                  [0,0,4,8],\n",
    "                  [16,4,8,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ce03f47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DynamicStepDriver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m frames\n\u001b[0;32m      4\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(tf_env\u001b[38;5;241m.\u001b[39mpyenv\u001b[38;5;241m.\u001b[39menvs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mrender(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m watch_driver \u001b[38;5;241m=\u001b[39m \u001b[43mDynamicStepDriver\u001b[49m(\n\u001b[0;32m      7\u001b[0m     tf_env,\n\u001b[0;32m      8\u001b[0m     agent\u001b[38;5;241m.\u001b[39mpolicy,\n\u001b[0;32m      9\u001b[0m     observers\u001b[38;5;241m=\u001b[39m[save_frames, ShowProgress(\u001b[38;5;241m1000\u001b[39m)],\n\u001b[0;32m     10\u001b[0m     num_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m     11\u001b[0m final_time_step, final_policy_state \u001b[38;5;241m=\u001b[39m watch_driver\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m     13\u001b[0m plot_animation(frames)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DynamicStepDriver' is not defined"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "def save_frames(trajectory):\n",
    "    global frames\n",
    "    frames.append(tf_env.pyenv.envs[0].render(mode=\"rgb_array\"))\n",
    "\n",
    "watch_driver = DynamicStepDriver(\n",
    "    tf_env,\n",
    "    agent.policy,\n",
    "    observers=[save_frames, ShowProgress(1000)],\n",
    "    num_steps=1000)\n",
    "final_time_step, final_policy_state = watch_driver.run()\n",
    "\n",
    "plot_animation(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1324b9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
